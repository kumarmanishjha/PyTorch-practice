{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 480      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.608   |\n",
      "|    explained_variance | -3.34    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -5.43    |\n",
      "|    value_loss         | 63.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 490      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.649   |\n",
      "|    explained_variance | -20.2    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 1.19     |\n",
      "|    value_loss         | 5.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 490      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.653   |\n",
      "|    explained_variance | -152     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 1.27     |\n",
      "|    value_loss         | 7.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 495      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.502   |\n",
      "|    explained_variance | -776     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 0.943    |\n",
      "|    value_loss         | 6.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 495      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.53    |\n",
      "|    explained_variance | -2.4e+04 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -3.58    |\n",
      "|    value_loss         | 222      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 497      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.45    |\n",
      "|    explained_variance | -872     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.55     |\n",
      "|    value_loss         | 4.64     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 497      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.442   |\n",
      "|    explained_variance | -3.1e+04 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -13.6    |\n",
      "|    value_loss         | 668      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 498       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.488    |\n",
      "|    explained_variance | -4.19e+04 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 0.806     |\n",
      "|    value_loss         | 4.59      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 496       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.431    |\n",
      "|    explained_variance | -1.11e+04 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 0.34      |\n",
      "|    value_loss         | 4.14      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 496       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.297    |\n",
      "|    explained_variance | -4.62e+04 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 0.177     |\n",
      "|    value_loss         | 3.65      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 495       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.289    |\n",
      "|    explained_variance | -1.72e+04 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 0.322     |\n",
      "|    value_loss         | 3.26      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 495       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.229    |\n",
      "|    explained_variance | -1.36e+05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 0.121     |\n",
      "|    value_loss         | 2.81      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 493       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.204    |\n",
      "|    explained_variance | -5.58e+05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 0.0832    |\n",
      "|    value_loss         | 2.42      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 492      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.216   |\n",
      "|    explained_variance | -4.7e+05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.0957   |\n",
      "|    value_loss         | 2.07     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 490       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.307    |\n",
      "|    explained_variance | -1.87e+05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 0.232     |\n",
      "|    value_loss         | 1.74      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 491       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.267    |\n",
      "|    explained_variance | -1.69e+04 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | 0.162     |\n",
      "|    value_loss         | 1.43      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 492       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.265    |\n",
      "|    explained_variance | -1.44e+06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 0.429     |\n",
      "|    value_loss         | 1.16      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 493       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.283    |\n",
      "|    explained_variance | -1.48e+05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 0.104     |\n",
      "|    value_loss         | 0.9       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 492      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.335   |\n",
      "|    explained_variance | -55.1    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -10.9    |\n",
      "|    value_loss         | 5.1e+03  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 492       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.291    |\n",
      "|    explained_variance | -1.71e+08 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 0.102     |\n",
      "|    value_loss         | 0.458     |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "from stable_baselines3 import A2C\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "model = A2C('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "obs = env.reset()\n",
    "for i in range(1000):\n",
    "    action, _state = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    if done:\n",
    "      obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import A2C\n",
    "\n",
    "model = A2C('MlpPolicy', 'CartPole-v1').learn(10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
